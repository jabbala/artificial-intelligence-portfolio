# Artificial Intelligence Portfolio
Welcome to my AI Portfolio! This portfolio showcases my journey, learnings, and projects in the exciting field of Artificial Intelligence. As a passionate AI enthusiast, I have dedicated time and effort to develop a strong foundation in various AI domains, and this portfolio serves as a testament to my dedication and skills.

## About Me
I am a dedicated and driven individual with a keen interest in AI and its applications. My journey into the world of AI began with a fascination for its potential to transform industries and improve lives. Through self-directed learning, online courses, and hands-on projects, I have cultivated a deep understanding of AI concepts and techniques.

## Table of Contents
* Sudoku Solver AI Agent
* Build a Forward Planning agent
* Build an Adversarial Game Playing Agent
* Parts of Speech Tagging
* Finding Shortest Paths on a Planet using Genetic Algorithm
* Solving the Maze Problem using Q-Learning
* AI Agent for Classic Snake Game using Deep Q-Learning Network (DQN)
* AI Agent for Double Headed Snake Game using Deep Q-Learning Network (DQN)
* Business Processes Optimization in E-Commerce Warehouse using Q-Learning
* Minimizing the Costs in Energy Consumption of a Data Center
* Self-Driving Car using Deep Q-Learning
* Doom using Deep Convolutional Q-learning
* Maximizing Revenue of an Online Retail Business through Thompson Sampling
* AI Agent for Breakout using Asynchronous Actor-Critic Agents (A3C)

## Portfolio Highlights

### Sudoku Solver AI Agent
The objective of this project is to build an AI agent capable of solving Sudoku puzzles using systematic approaches. Sudoku, a logic-based number-placement puzzle, challenges players to fill a 9x9 grid with digits so that each column, each row, and each of the nine 3x3 subgrids that compose the grid contain all the digits from 1 to 9. Our AI agent uses a combination of backtracking and constraint propagation to deduce and place the correct digits in the puzzle.

#### Conclusion
The Sudoku Solver AI Agent project demonstrates how algorithms and intelligent techniques can efficiently tackle complex puzzles. By utilizing a combination of backtracking and constraint propagation, the agent systematically solves Sudoku puzzles, showcasing the potential of AI in problem-solving domains.

### Forward Planning Agent
The goal of this project is to build a Forward Planning Agent that can effectively navigate and solve problems in dynamic environments. Forward planning involves making decisions to achieve a specific goal while considering possible outcomes and uncertainties. Our AI agent uses a combination of search algorithms, heuristics, and domain knowledge to plan actions that lead to successful outcomes.

#### Conclusion
The Forward Planning Agent project showcases the intelligence and adaptability of AI in solving complex problems. By combining search algorithms, heuristics, and domain knowledge, the agent demonstrates its capability to plan and execute actions that lead to desired outcomes.

### Adversarial Game Playing Agent
The objective of this project is to build an Adversarial Game Playing Agent capable of making strategic decisions in two-player adversarial games. Adversarial games, like chess or tic-tac-toe, challenge players to outwit their opponents through thoughtful moves and predictive analysis. Our AI agent uses search algorithms and evaluation functions to anticipate opponent actions and choose the best possible moves.

#### Conclusion
The Adversarial Game Playing Agent project demonstrates the strategic prowess of AI in competitive environments. By utilizing adversarial search algorithms like minimax and alpha-beta pruning, the agent makes intelligent decisions that optimize its chances of success against opponents.

### Parts of Speech Tagging with AI
The goal of this project is to build a Parts of Speech Tagging model that can accurately classify words into different grammatical categories, such as nouns, verbs, adjectives, and more. Parts of speech tagging is a fundamental task in NLP and serves as a crucial step in various text processing applications, including language understanding, sentiment analysis, and information retrieval. Our AI model utilizes machine learning algorithms and annotated datasets to learn patterns and associations between words and their respective parts of speech.

##### Conclusion
The Parts of Speech Tagging project demonstrates the application of AI in understanding the grammatical structure of natural language. By leveraging annotated data and machine learning techniques, the model can accurately assign parts of speech tags to words, contributing to various text processing and language analysis tasks.

### Finding Shortest Paths on a Planet using Genetic Algorithm
The primary objective of this project is to build a pathfinding system that uses a Genetic Algorithm to find the shortest path between different locations on a planet. Genetic algorithms are inspired by natural evolution and involve generating multiple potential solutions (individuals), selecting the best ones through fitness evaluation, and iteratively improving the population over generations. Our Genetic Algorithm will create and refine potential paths to find the optimal route for travel between locations.
#### Conclusion
The Shortest Path Finding project using Genetic Algorithm showcases the power of evolutionary algorithms in solving optimization problems. By mimicking the principles of natural selection and genetic inheritance, the Genetic Algorithm discovers the shortest paths between locations on a planet's surface.

### Solving The Maze Problem using Q-learning
The maze problem involves a grid-like environment where an agent needs to find the optimal path from a start location to a goal location while avoiding obstacles. Traditional pathfinding algorithms might not work well in complex scenarios, so we turn to Q-Learning, a reinforcement learning technique, to enable the agent to learn the best actions to take in order to reach the goal while avoiding obstacles.

#### Q-Learning Explanation
Q-Learning involves learning a Q-value table that represents the expected rewards for taking different actions in different states. In our case, states are the positions within the maze, and actions are the agent's movements (up, down, left, right). The agent updates Q-values using the Bellman equation, which takes into account the immediate reward and the expected future rewards.

#### Conclusion
The "Solving the Maze Problem using Q-Learning" project demonstrates how AI can be used to solve complex pathfinding challenges through reinforcement learning. By allowing the agent to learn from trial and error, we enable it to make intelligent decisions and efficiently navigate through mazes.

### AI Agent for Classic Snake Game using Deep Q-Learning Network (DQN)
The classic Snake game challenges players to navigate a snake through a grid while collecting food to grow longer. The game ends if the snake collides with the walls or itself. We'll employ the Deep Q-Learning Network (DQN) to train an AI agent to learn how to play the game effectively. DQN is a powerful algorithm that leverages neural networks to approximate Q-values and make decisions.

#### Deep Q-Learning Network (DQN) Explanation
DQN combines reinforcement learning with deep neural networks. The agent learns to approximate Q-values (expected future rewards) using a neural network. The network takes the current state (game screen) as input and outputs Q-values for each possible action. DQN uses experience replay and target networks to stabilize learning and prevent instability.

#### Conclusion
The "AI Agent for Classic Snake Game using Deep Q-Learning Network (DQN)" project showcases the potential of deep reinforcement learning in solving complex gaming challenges. By training a neural network to approximate Q-values, the DQN agent learns effective strategies to navigate and play the Snake game optimally.

### AI Agent for Double Headed Snake Game using Deep Q-Learning Network (DQN)
The double-headed Snake game presents a unique challenge where the snake can move in both forward and backward directions. This adds complexity to the navigation and decision-making process. We'll enhance the Deep Q-Learning Network (DQN) approach to handle this scenario and train an AI agent that can play the game effectively, accounting for bidirectional movement.

#### Enhanced Deep Q-Learning Network (DQN) Explanation
To accommodate bidirectional movement, we'll extend the DQN algorithm to output Q-values for both forward and backward actions for each head of the snake. The agent will learn to select actions for both heads, optimizing its strategy based on the potential rewards and avoiding collisions.

#### Conclusion
The "AI Agent for Double Headed Snake Game using Deep Q-Learning Network (DQN)" project showcases the adaptation of deep reinforcement learning to handle bidirectional movement challenges. By extending the DQN algorithm, the agent learns effective strategies to navigate and play the Double Headed Snake game optimally.

### Business Processes Optimization in E-Commerce Warehouse using Q-Learning
In the fast-paced world of e-commerce, warehouse operations play a crucial role in meeting customer demands. This project focuses on leveraging Q-Learning, a powerful reinforcement learning algorithm, to optimize business processes within an e-commerce warehouse. The Q-Learning agent learns to make decisions that lead to improved inventory management, effective order fulfillment, and optimal resource allocation, ultimately enhancing the overall efficiency of the warehouse.

#### Results and Evaluation
The project logs the progress of the Q-Learning agent as it optimizes warehouse operations over multiple episodes. You can track the agent's decision-making and the total rewards obtained at each step of the optimization process.

### Minimizing the Costs in Energy Consumption of a Data Center
As data centers play a critical role in today's digital landscape, optimizing their energy consumption is paramount. This project focuses on utilizing Deep Q-Learning, a cutting-edge reinforcement learning technique, to minimize energy costs while maintaining the performance and reliability of data center services. By training an AI agent to make energy-efficient decisions, we strive to contribute to both cost savings and environmental conservation.

#### Results and Evaluation
The project records the agent's progress as it learns to make energy-efficient decisions within the data center environment. You can track the agent's actions, cumulative rewards, and energy consumption over the course of training.

### Self-Driving Car using Deep Q-Learning
The goal of this project was to create an AI agent capable of navigating a virtual environment and driving a car safely while optimizing its path and avoiding obstacles. I chose to implement Deep Q-Learning, a prominent technique in the field of reinforcement learning, to train the agent's decision-making capabilities.

### AI Agent for Doom using Deep Convolutional Q-learning
The project's primary goal was to develop an AI agent that could autonomously navigate the challenging landscapes of the DOOM game. Through the implementation of Deep Convolutional Q-Learning, a variant of traditional Q-learning designed to handle high-dimensional state spaces like images, the agent aimed to learn optimal strategies for survival, exploration, and successful mission completion.

### Maximizing Revenue of an Online Retail Business through Thompson Sampling
In the competitive world of online retail, making informed decisions about which products to promote is crucial for driving revenue. This project focuses on utilizing Thompson Sampling, a Bayesian approach, to address the product selection challenge. By training an AI agent using historical user interactions, we seek to recommend products that have the potential to yield the highest revenue based on user preferences and uncertainty.

#### Results and Evaluation
The project tracks the agent's performance as it learns to choose products that maximize revenue. You can monitor the selected products, their associated rewards, and the overall revenue generated over time.

### AI Agent for Breakout using Asynchronous Actor-Critic Agents (A3C)
The A3C algorithm is a state-of-the-art method for training deep reinforcement learning agents. It combines the strengths of policy-based and value-based methods, allowing for more stable and efficient learning. In this project, I applied the A3C algorithm to the Breakout game, enabling an AI agent to learn optimal strategies for achieving high scores through trial and error.

## References
* Arthur Juliani, 2016, Simple Reinforcement Learning with Tensorflow (10 Parts)
* Richard Sutton et al., 1998, Reinforcement Learning I: Introduction
* Richard Bellman, 1954, The Theory of Dynamic Programming
* D. J. White, 1993, A Survey of Applications of Markov Decision Processes
* Martijn van Otterlo, 2009, Markov Decision Processes: Concepts and Algorithms
* Richard Sutton, 1988, Learning to Predict by the Methods of Temporal Differences
* Arthur Juliani, 2016, Simple Reinforcement Learning with Tensorflow (Part 4)
* Tom Schaul et al., Google DeepMind, 2016, Prioritized Experience Replay
* Michel Tokic, 2010, Adaptive ε-greedy Exploration in Reinforcement Learning Based on Value Differences
* Richard S. Sutton and Andrew G. Barto, 1998, Reinforcement Learning: An Introduction
* Volodymyr Mnih et al., 2016, Asynchronous Methods for Deep Reinforcement Learning
* Volodymyr Mnih et al, 2016  Asynchronous Methods for Deep Reinforcement Learning
* Jaromír Janisch, 2017 Let’s Make An A3c: Implementation
* John Schulman et al., 2016 High-dimensional Continuous Control Using Generalized Advantage Estimation
* Arthur Juliani, 2016 Simple Reinforcement Learning with Tensorflow (Part 8)

Connect with me on <a href="https://www.linkedin.com/in/jabbala">LinkedIn</a> to discuss this project or other AI endeavors. Let's drive innovation together!
